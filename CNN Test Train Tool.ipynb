{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO/WWY24bf332AIq8KL68+n"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"zw19jELtSFPe"},"outputs":[],"source":["#@title Balance Dataset from folder\n","import os\n","import shutil\n","import numpy as np\n","from PIL import Image\n","from imblearn.over_sampling import RandomOverSampler\n","from multiprocessing import Pool\n","from tqdm import tqdm  # For progress bar\n","\n","def balance_load_images_and_labels(dataset_path):\n","    \"\"\"Load all images and their class labels from a dataset folder.\"\"\"\n","    images = []\n","    labels = []\n","    image_paths = []\n","\n","    class_dirs = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n","    for class_label, class_dir in enumerate(class_dirs):\n","        class_path = os.path.join(dataset_path, class_dir)\n","        for filename in os.listdir(class_path):\n","            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n","                img_path = os.path.join(class_path, filename)\n","                image_paths.append(img_path)\n","                labels.append(class_dir)\n","\n","    return image_paths, labels\n","\n","def balance_load_image_and_convert(path, resize):\n","    \"\"\"Loads an image, resizes it, and converts it to a NumPy array.\"\"\"\n","    img = Image.open(path).convert('RGB')  # Convert image to RGB\n","    if resize:\n","        img = img.resize(resize)  # Resize image\n","    return np.array(img), path\n","\n","def balance_save_image(img_array, dest_path):\n","    \"\"\"Saves an image from a NumPy array to a specified path.\"\"\"\n","    img = Image.fromarray(img_array)\n","    img.save(dest_path)\n","\n","def balance_process_image(path_resize):\n","    \"\"\"Helper function to be used with Pool to load and resize images.\"\"\"\n","    path, resize = path_resize\n","    return balance_load_image_and_convert(path, resize)\n","\n","def balance_dataset(dataset_path, resize=None):\n","    \"\"\"Balances the dataset by resizing images, oversampling each class, and creates a new balanced dataset.\"\"\"\n","    # Create a new dataset folder with \"-balanced\" suffix\n","    parent_dir, dataset_name = os.path.split(dataset_path)\n","    new_dataset_name = dataset_name + \"-balanced\"\n","    new_dataset_path = os.path.join(parent_dir, new_dataset_name)\n","    os.makedirs(new_dataset_path, exist_ok=True)\n","\n","    # Load all images and labels\n","    print(\"Loading images and labels...\")\n","    image_paths, labels = balance_load_images_and_labels(dataset_path)\n","\n","    # Prepare tuples of (image path, resize) for each image\n","    path_resize_tuples = [(path, (resize, resize)) for path in image_paths]\n","\n","    # Load and resize images into a NumPy array using multiprocessing with a progress bar\n","    print(f\"Loading and resizing {len(image_paths)} images...\")\n","    with Pool() as pool:\n","        images_with_paths = list(tqdm(pool.imap(balance_process_image, path_resize_tuples), total=len(image_paths)))\n","\n","    images = np.array([item[0] for item in images_with_paths])  # Extract images\n","    paths = [item[1] for item in images_with_paths]  # Extract paths\n","\n","    n_samples, height, width, channels = images.shape\n","    flat_images = images.reshape(n_samples, -1)  # Flatten images for oversampling\n","\n","    # Apply RandomOverSampler across all classes\n","    print(\"Applying RandomOverSampler to balance the dataset...\")\n","    ros = RandomOverSampler()\n","    flat_images_resampled, labels_resampled = ros.fit_resample(flat_images, np.array(labels))\n","\n","    # Reshape images back to original format\n","    images_resampled = flat_images_resampled.reshape(-1, height, width, channels)\n","\n","    # Save resampled images into appropriate class folders in the new dataset\n","    print(\"Saving resampled images...\")\n","    for img_array, label in tqdm(zip(images_resampled, labels_resampled), total=len(images_resampled)):\n","        class_dir = os.path.join(new_dataset_path, label)\n","        os.makedirs(class_dir, exist_ok=True)\n","\n","        img_index = len(os.listdir(class_dir))  # To create unique filenames\n","        dest_path = os.path.join(class_dir, f\"resampled_{img_index}.jpg\")\n","        balance_save_image(img_array, dest_path)\n","\n","    print(f\"Balanced dataset created at {new_dataset_path}\")\n","\n","dataset_path = '/mnt/e/Universitate/Doctorat/2024/Articol-Jurnal/skin-cancer/skins'\n","balance_dataset(dataset_path, 32)"]},{"cell_type":"code","source":["#@title Dataset from folder\n","\n","import os\n","gpu_device_number = 0\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_device_number)\n","import tensorflow as tf\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","print(\"Available GPUs:\", gpus)\n","current_gpu = tf.config.experimental.get_visible_devices('GPU')\n","print(\"Current GPU:\", current_gpu)\n","\n","if gpus:\n","    try:\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)  # Prevents TensorFlow from consuming all GPU memory at once\n","    except RuntimeError as e:\n","        print(e)\n","\n","import numpy as np\n","import shutil\n","import time as ti\n","from multiprocessing import Pool\n","from functools import partial\n","from tqdm import tqdm\n","from itertools import chain\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","import random\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from imblearn.over_sampling import RandomOverSampler\n","\n","def save_image(idx, path, path_export, labels, classes, img, copy_only = True):\n","    current_class = classes[np.where(labels[idx] == 1)[0][0]]\n","    class_dir = os.path.join(path_export, current_class)\n","    channels = img.mode\n","    r = str(random.randrange(1,1000))\n","    if copy_only == False:\n","      im_path = os.path.join(class_dir, f\"{str(idx)+r}-augment.png\")\n","      if channels != \"RGB\":\n","        print(im_path)\n","      if not os.path.exists(im_path):\n","        img.save(im_path)\n","    else:\n","      img_name = os.path.basename(path)\n","      im_path = os.path.join(class_dir, img_name)\n","      if channels != \"RGB\":\n","        print(im_path)\n","      if not os.path.exists(im_path):\n","        shutil.copy(path, im_path)\n","\n","def load_image(idx, file_path, target_size, labels, classes, augment, path_export = None):\n","    images = []\n","    copy_only = True\n","\n","    im = Image.open(file_path)\n","    width, height = im.size\n","    if width != target_size[0] or height != target_size[1]:\n","      im = im.resize(target_size, Image.LANCZOS)\n","      copy_only = False\n","    images.append(np.array(im))\n","\n","    if path_export != None:\n","      if copy_only == True:\n","        save_image(idx, file_path, path_export, labels, classes, im)\n","      else:\n","        save_image(idx, file_path, path_export, labels, classes, im, False)\n","\n","    if augment > 0:\n","      # datagen_augment = ImageDataGenerator(rotation_range=10, width_shift_range=0.2, height_shift_range=0.2, zoom_range=0.2, horizontal_flip=True, brightness_range=[0.2,1.2])\n","      datagen_augment = ImageDataGenerator(rotation_range=60, horizontal_flip=True, brightness_range=[1,1.2])\n","      np_image = np.asarray(im)\n","      np_image = np.reshape(np_image, (1,) + np_image.shape)\n","      augment_generator = datagen_augment.flow(np_image, batch_size=1)\n","      for i in range(augment-1):\n","        gen_img = next(augment_generator)[0].astype(np.uint8)\n","        images.append(gen_img.squeeze())\n","        if path_export != None:\n","          im = Image.fromarray(gen_img.squeeze())\n","          save_image(idx, file_path, path_export, labels, classes, im, False)\n","\n","    return idx, images\n","\n","def load_image_with_progress(idx, image, target_size, labels, classes, augment,  path_export = None):\n","    return load_image(idx, image, target_size=target_size, labels=labels, classes=classes, augment=augment, path_export = path_export)\n","\n","def load_images_with_progress(images, target_size, labels, classes, augment, path_export=None):\n","    with Pool(processes=6) as pool:\n","        partial_func = partial(load_image_with_progress_wrapper, target_size=target_size, labels=labels, classes=classes, augment=augment, path_export=path_export)\n","        results = list(tqdm(pool.imap(partial_func, enumerate(images)), total=len(images)))\n","        indices, processed_images = zip(*results)\n","    return list(chain.from_iterable(processed_images))\n","\n","def load_image_with_progress_wrapper(args, target_size, labels, classes, augment, path_export):\n","    idx, image = args\n","    return load_image_with_progress(idx, image, target_size=target_size, labels=labels, classes=classes, augment=augment, path_export=path_export)\n","\n","def normalize(image, label):\n","  normalization_layer = tf.keras.layers.Rescaling(1./255)\n","  return normalization_layer(image), label\n","\n","def dataset(path, reload=False, width=0, augment=0, batch_size = 20, load_from_dir = False):\n","    t_start = ti.time()\n","\n","    target_size = (width, width)\n","    folder = os.path.basename(path)\n","\n","    if augment > 0:\n","        if augment > 2:\n","          folder += \"-\" + str(augment) + \"-augmented\"\n","        else:\n","          folder += \"-augmented\"\n","        datagen_augment = ImageDataGenerator(\n","            rotation_range=360, horizontal_flip=True, brightness_range=[1, 1.2]\n","        )\n","\n","    if load_from_dir == False:\n","      folder += \"-test\"\n","\n","    images = []\n","    original_labels = []\n","    labels = []\n","    total_class_images = []\n","    classes = []\n","    num_classes = 0\n","    total_images = 0\n","    idx = -1\n","\n","    for root, dirs, files in os.walk(path):\n","        if num_classes == 0 and dirs:\n","            num_classes = len(dirs)\n","            classes = dirs\n","        else:\n","            idx += 1\n","            total_class_images.append(0)\n","\n","        empty_label = np.zeros(num_classes)\n","        empty_label[idx] = 1\n","\n","        for img in files:\n","            _, file_extension = os.path.splitext(img)\n","            if file_extension.lower() in (\".png\", \".jpg\", \".jpeg\"):\n","                total_images += 1\n","                total_class_images[idx] += 1\n","                file_path = os.path.join(root, img)\n","                images.append(file_path)\n","                labels.append(empty_label)\n","                original_labels.append(empty_label)\n","                if augment > 0:\n","                  for i in range(augment-1):\n","                    labels.append(empty_label)\n","                    total_images += 1\n","                    total_class_images[idx] += 1\n","\n","    if width > 0:\n","        folder += f\"-{width}x{width}\"\n","\n","    path_export = os.path.join(os.path.dirname(path), folder)\n","    if reload and os.path.exists(path_export):\n","        delete_all(path_export)\n","\n","    print(\"Dataset path:\", path_export)\n","    print(\"Total images:\", total_images)\n","    print(\"Target Width:\", width)\n","    print(\"Target height:\", width)\n","\n","    x_train, x_test, y_train, y_test = train_test_split(images, original_labels, test_size=0.2)\n","    x_valid, x_test, y_valid, y_test = train_test_split(x_test, y_test, test_size=0.5)\n","\n","    # Multiprocessing to load images\n","    if load_from_dir == False:\n","      x_train = load_images_with_progress(x_train, target_size=target_size, labels=y_train, classes=classes, augment=augment)\n","      x_valid = load_images_with_progress(x_valid, target_size=target_size, labels=y_valid, classes=classes, augment=augment)\n","      for current_class in classes:\n","        class_dir = os.path.join(path_export, current_class)\n","        if not os.path.exists(class_dir):\n","            os.makedirs(class_dir, True)\n","      x_test = load_images_with_progress(x_test, target_size=target_size, labels=y_test, classes=classes, augment=augment, path_export=path_export)\n","\n","      # Convert to numpy arrays\n","      x_train = np.array(x_train).astype('float32') / 255\n","      x_valid = np.array(x_valid).astype('float32') / 255\n","      x_test = np.array(x_test).astype('float32') / 255\n","\n","      y_train = np.array(y_train).astype('float32')\n","      y_valid = np.array(y_valid).astype('float32')\n","      y_test = np.array(y_test).astype('float32')\n","\n","    else:\n","      if not os.path.exists(path_export + '/train'):\n","        for current_class in classes:\n","          class_dir = os.path.join(path_export + '/train', current_class)\n","          if not os.path.exists(class_dir):\n","              os.makedirs(class_dir, True)\n","        load_images_with_progress(x_train, target_size=target_size, labels=y_train, classes=classes, augment=augment, path_export=path_export + '/train')\n","        for current_class in classes:\n","          class_dir = os.path.join(path_export + '/valid', current_class)\n","          if not os.path.exists(class_dir):\n","              os.makedirs(class_dir, True)\n","        load_images_with_progress(x_valid, target_size=target_size, labels=y_valid, classes=classes, augment=augment, path_export=path_export + '/valid')\n","        for current_class in classes:\n","          class_dir = os.path.join(path_export + '/test', current_class)\n","          if not os.path.exists(class_dir):\n","              os.makedirs(class_dir, True)\n","        load_images_with_progress(x_test, target_size=target_size, labels=y_test, classes=classes, augment=augment, path_export=path_export + '/test')\n","\n","      train_ds = tf.keras.utils.image_dataset_from_directory(path_export + '/train',label_mode=\"categorical\", image_size=target_size, batch_size=batch_size)\n","      normalized_train_ds = train_ds.map(normalize)\n","      normalized_train_ds = normalized_train_ds.prefetch(tf.data.experimental.AUTOTUNE)\n","\n","      valid_ds = tf.keras.utils.image_dataset_from_directory(path_export + '/valid',label_mode=\"categorical\", image_size=target_size, batch_size=batch_size)\n","      normalized_valid_ds = valid_ds.map(normalize)\n","      normalized_valid_ds = normalized_valid_ds.prefetch(tf.data.experimental.AUTOTUNE)\n","\n","      test_ds = tf.keras.utils.image_dataset_from_directory(path_export + '/test',label_mode=\"categorical\", image_size=target_size, batch_size=batch_size)\n","      normalized_test_ds = test_ds.map(normalize)\n","      normalized_test_ds = normalized_test_ds.prefetch(tf.data.experimental.AUTOTUNE)\n","\n","    t_stop = ti.time()\n","    print('Dataset loading time:', round((t_stop - t_start), 2), 'seconds')\n","\n","    if load_from_dir == True:\n","      return normalized_train_ds, normalized_valid_ds, normalized_test_ds, width, width, folder, num_classes\n","    else:\n","      return (x_train, y_train), (x_valid, y_valid), (x_test, y_test), width, width, folder, num_classes\n","\n","def delete_all(folder):\n","    for filename in os.listdir(folder):\n","        file_path = os.path.join(folder, filename)\n","        try:\n","            if os.path.isfile(file_path) or os.path.islink(file_path):\n","                os.unlink(file_path)\n","            elif os.path.isdir(file_path):\n","                shutil.rmtree(file_path)\n","        except Exception as e:\n","            print(\"Failed to delete %s. Reason: %s\" % (file_path, e))\n","    try:\n","        shutil.rmtree(folder)\n","    except Exception as e:\n","        print(\"Failed to delete %s. Reason: %s\" % (folder, e))\n","\n","# Example usage:\n","# dataset_path = '/path/to/your/dataset'\n","# (x_train, y_train), (x_valid, y_valid), (x_test, y_test), target_width, target_height, folder, num_classes = dataset(dataset_path, reload=True, width=224, augment=2)\n"],"metadata":{"cellView":"form","id":"oaJ_HQueSM1D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Dataset from Tensorflow API\n","\n","import os\n","gpu_device_number = 0\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_device_number)\n","import tensorflow as tf\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","print(\"Available GPUs:\", gpus)\n","current_gpu = tf.config.experimental.get_visible_devices('GPU')\n","print(\"Current GPU:\", current_gpu)\n","\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","import os\n","import numpy as np\n","import time as ti\n","from PIL import Image\n","\n","def preprocess_data(image, label, channels, num_classes, size, resize):\n","    img_weight, img_height, img_channel = image.shape\n","    if resize == True:\n","      image = tf.image.resize(image, (size, size))\n","    if img_channel != channels:\n","      image = tf.concat(channels, axis=-1)\n","    label = tf.one_hot(label, depth=num_classes)\n","    return image, label\n","\n","def dataset(dataset, path=\"\", channels = 3, augment=0, split = ['train','validation']):\n","    t_start = ti.time()\n","\n","    train, test = tfds.load(dataset, split=split, as_supervised = True)\n","    if augment > 1:\n","      train.repeat(augment)\n","      test.repeat(augment)\n","\n","    total_train_images = len(train)\n","    total_test_images = len(test)\n","    total_images = total_train_images + total_test_images\n","\n","    test_labels = [label.numpy() for _, label in test]\n","    num_classes = len(set(test_labels))\n","\n","    valid = test.skip(total_test_images // 2)\n","    test = test.take(total_test_images // 2)\n","\n","    width, height = 0, 0\n","    resize = False\n","    for image, label in test:\n","        width, height, _ = image.shape\n","        break\n","    if width != height:\n","      resize = True\n","      if width > height:\n","        width = height\n","      else:\n","        height = width\n","\n","    folder = dataset\n","    if width > 0:\n","        folder += f\"-{width}x{height}\"\n","\n","    print(\"Number of classes:\", num_classes)\n","    print(\"Total images:\", total_images)\n","    print(\"Target Width:\", width)\n","    print(\"Target height:\", height)\n","\n","    train_preprocessed = train.map(lambda image, label: preprocess_data(image, label, channels, num_classes, width, resize))\n","    test_preprocessed = test.map(lambda image, label: preprocess_data(image, label, channels, num_classes, width, resize))\n","    valid_preprocessed = valid.map(lambda image, label: preprocess_data(image, label, channels, num_classes, width, resize))\n","\n","    if path:\n","      path_export = os.path.join(path, folder)\n","      print(\"Dataset export path:\", path_export)\n","      if not os.path.exists(path_export):\n","          os.makedirs(path_export)\n","          no = 0;\n","          for image, label in test_preprocessed:\n","            current_class = str(tf.argmax(label, axis=-1).numpy())\n","            class_dir = os.path.join(path_export, current_class)\n","            if not os.path.exists(class_dir):\n","                os.makedirs(class_dir)\n","            img_array = image.numpy()\n","            if np.min(img_array) >= 0 and np.max(img_array) <= 1:\n","                img_array = (img_array * 255).astype(np.uint8)\n","            else:\n","                img_array = img_array.astype(np.uint8)\n","            im = Image.fromarray(img_array)\n","            im.save(os.path.join(class_dir, f\"{no}.png\"))\n","            no += 1\n","\n","    # Unpack the preprocessed datasets\n","    x_train, y_train = zip(*train_preprocessed)\n","    x_test, y_test = zip(*test_preprocessed)\n","    x_valid, y_valid = zip(*valid_preprocessed)\n","\n","    # Convert to numpy arrays\n","    x_train = np.array(x_train).astype('float32') / 255\n","    x_valid = np.array(x_valid).astype('float32') / 255\n","    x_test = np.array(x_test).astype('float32') / 255\n","\n","    y_train = np.array(y_train).astype('float32')\n","    y_valid = np.array(y_valid).astype('float32')\n","    y_test = np.array(y_test).astype('float32')\n","\n","    t_stop = ti.time()\n","    print('Dataset loading time:', round((t_stop - t_start), 2), 'seconds')\n","\n","    return (x_train, y_train), (x_valid, y_valid), (x_test, y_test), width, height, folder, num_classes\n","\n","# Example usage:\n","# dataset_export_path = '/path/to/your/dataset'\n","# (x_train, y_train), (x_valid, y_valid), (x_test, y_test), target_width, target_height, folder, num_classes = dataset('mnist', path=dataset_export_path, channels = 3, augment = 2)\n"],"metadata":{"cellView":"form","id":"10tFhX0jSWXH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Training\n","import tensorflow as tf\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","import matplotlib.pyplot as plt\n","import openpyxl\n","import os\n","import time as ti\n","\n","def train(model_name, model, epochs, train_data, validation_data, test_data, dataset_name, dataset_path, batch_size = 20, use_generator_from_dir = False, patience=20):\n","\n","  folder = '';\n","  path_list = dataset_path.split('/')\n","  if len(path_list) > 0:\n","    folder = path_list.pop(-1)\n","  else:\n","    folder = 'dataset'\n","\n","  path_export = '/'.join(path_list)\n","\n","  early_stopping = EarlyStopping(monitor='val_accuracy', patience=patience, restore_best_weights=True, verbose=0)\n","  checkpoint = ModelCheckpoint(path_export + '/trained-models-' + folder + '/' + model_name + '-' + dataset_name + \".keras\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n","\n","  if use_generator_from_dir:\n","    t1=ti.time()\n","    history = model.fit(train_data, validation_data=validation_data, epochs=epochs, shuffle=True, verbose=1, batch_size=batch_size, callbacks=[checkpoint, early_stopping])\n","    t2=ti.time()\n","\n","    t_start = ti.time()\n","    score = model.evaluate(test_data, verbose=0)\n","    t_stop = ti.time()\n","  else:\n","    print(\"Input shape:\", train_data[0].shape)\n","    t1=ti.time()\n","    history = model.fit(train_data[0], train_data[1], validation_data=validation_data, epochs=epochs, shuffle=True, verbose=1, batch_size=batch_size, callbacks=[checkpoint, early_stopping])\n","    t2=ti.time()\n","\n","    t_start = ti.time()\n","    score = model.evaluate(test_data[0],test_data[1], verbose=0)\n","    t_stop = ti.time()\n","\n","  if not os.path.exists(path_export + '/centralizator-' + folder + '.xlsx'):\n","    workbook = openpyxl.Workbook()\n","  else:\n","    workbook = openpyxl.load_workbook(path_export + '/centralizator-' + folder + '.xlsx')\n","\n","  sheet_name = dataset_name\n","\n","  if 'Sheet' in workbook.sheetnames:\n","    del workbook['Sheet']\n","\n","  if not sheet_name in workbook.sheetnames:\n","    workbook.create_sheet(sheet_name)\n","\n","  sheet = workbook[sheet_name]\n","\n","  model_idx = ''\n","  for i in range(2, len(sheet['A'])+1):\n","    if sheet['A' + str(i)].value == model_name:\n","      model_idx = str(i)\n","\n","  if model_idx == '':\n","    model_idx = str(len(sheet['A']) + 1)\n","\n","  accuracy = round(100*score[1],2)\n","  sheet['P' + model_idx] = str(accuracy) + \"%, \" + str(ti.ctime(ti.time()))\n","  print('Test accuracy: ' + str(accuracy) + \"%\")\n","\n","  if sheet['D' + model_idx].value is None or float(sheet['D' + model_idx].value) < accuracy:\n","    if not os.path.exists(path_export + '/trained-models-' + folder):\n","      os.mkdir(path_export + '/trained-models-' + folder)\n","\n","    model = tf.keras.models.load_model(path_export + '/trained-models-' + folder + '/' + model_name + '-' + dataset_name + \".keras\")\n","\n","    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","    converter.target_spec.supported_ops = [\n","      tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n","      tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n","    ]\n","    tflite_model = converter.convert()\n","    open(path_export + '/trained-models-' + folder + '/' + model_name + '-' + dataset_name + '.tflite', \"wb\").write(tflite_model)\n","\n","    if use_generator_from_dir:\n","      train_data = train_data.take(-1)\n","      train_dataset_length = tf.data.experimental.cardinality(train_data).numpy() * batch_size\n","      validation_data = validation_data.take(-1)\n","      valid_dataset_length = tf.data.experimental.cardinality(validation_data).numpy() * batch_size\n","      test_data = test_data.take(-1)\n","      test_dataset_length = tf.data.experimental.cardinality(test_data).numpy() * batch_size\n","    else:\n","      train_dataset_length = len(train_data)\n","      valid_dataset_length = len(validation_data)\n","      test_dataset_length = len(test_data)\n","\n","    sheet['A1'] = 'Model'\n","    sheet['B1'] = 'Training Acc [%]'\n","    sheet['C1'] = 'Valid Acc [%]'\n","    sheet['D1'] = 'Test Acc (on Colab) [%]'\n","    sheet['E1'] = 'Latency (on Colab) [ms]'\n","    sheet['F1'] = 'Training time [s]'\n","    sheet['G1'] = 'Validation time [s]'\n","\n","    sheet['H1'] = 'Params (M)'\n","    sheet['I1'] = 'TFLite size [MB]'\n","    sheet['J1'] = 'Model size [MB]'\n","    sheet['K1'] = 'FLOPS (M)'\n","\n","    sheet['L1'] = 'Test Acc (on Android) [%]'\n","    sheet['M1'] = 'Latency (on Android) [ms]'\n","    sheet['N1'] = 'Test time (on Android) [s]'\n","\n","    sheet['O1'] = 'Updated at'\n","    sheet['P1'] = 'Last try'\n","    sheet['Q1'] = 'Observatii'\n","\n","    sheet['A' + model_idx] = model_name\n","    sheet['B' + model_idx] = round(100*max(history.history['accuracy']),2)\n","    sheet['C' + model_idx] = round(100*max(history.history['val_accuracy']),2)\n","    sheet['D' + model_idx] = accuracy\n","    sheet['E' + model_idx] = round(((t_stop-t_start)/test_dataset_length)*1000,2)\n","    sheet['F' + model_idx] = round((t2-t1),2)\n","    sheet['G' + model_idx] = round((t_stop-t_start),2)\n","\n","    sheet['H' + model_idx] = round(model.count_params()/1000000,2)\n","    sheet['I' + model_idx] = round(os.path.getsize(path_export + '/trained-models-' + folder + '/' + model_name + '-' + dataset_name + '.tflite')/1024/1024,2)\n","    sheet['J' + model_idx] = round(os.path.getsize(path_export + '/trained-models-' + folder + '/' + model_name + '-' + dataset_name + '.keras')/1024/1024,2)\n","    sheet['K' + model_idx] = round(get_flops(path_export + '/trained-models-' + folder + '/' + model_name + '-' + dataset_name + '.keras')/1000000,2)\n","\n","    sheet['O' + model_idx] = ti.ctime(ti.time())\n","    sheet['Q' + model_idx] = \"Total images: \" + str(train_dataset_length+valid_dataset_length+test_dataset_length) + \", Train images: \" + str(train_dataset_length) + \", Validation images: \" + str(valid_dataset_length) + \", Test images: \" + str(test_dataset_length)\n","\n","    if isinstance(sheet['B2'].value, int) or isinstance(sheet['B2'].value, float):\n","      valoare_maxima = float(sheet['B2'].value)\n","      indice_maxim = 2\n","\n","      for i in range(2, len(sheet['B'])+1):\n","        sheet['B' + str(i)].font = openpyxl.styles.Font(bold=False)\n","        if isinstance(sheet['B' + str(i)].value, int) or isinstance(sheet['B' + str(i)].value, float):\n","          valoare = float(sheet['B' + str(i)].value)\n","          if valoare is not None and valoare > valoare_maxima:\n","              valoare_maxima = valoare\n","              indice_maxim = i\n","\n","      sheet['B' + str(indice_maxim)].font = openpyxl.styles.Font(bold=True)\n","\n","    if isinstance(sheet['D2'].value, int) or isinstance(sheet['D2'].value, float):\n","      valoare_maxima = float(sheet['D2'].value)\n","      indice_maxim = 2\n","\n","      for i in range(2, len(sheet['D'])+1):\n","        sheet['D' + str(i)].font = openpyxl.styles.Font(bold=False)\n","        if isinstance(sheet['D' + str(i)].value, int) or isinstance(sheet['D' + str(i)].value, float):\n","          valoare = float(sheet['D' + str(i)].value)\n","          if valoare is not None and valoare > valoare_maxima:\n","              valoare_maxima = valoare\n","              indice_maxim = i\n","\n","      sheet['D' + str(indice_maxim)].font = openpyxl.styles.Font(bold=True)\n","\n","    if isinstance(sheet['E2'].value, int) or isinstance(sheet['E2'].value, float):\n","      valoare_minima = float(sheet['E2'].value)\n","      indice_minim = 2\n","\n","      for i in range(2, len(sheet['E'])+1):\n","        sheet['E' + str(i)].font = openpyxl.styles.Font(bold=False)\n","        if isinstance(sheet['E' + str(i)].value, int) or isinstance(sheet['E' + str(i)].value, float):\n","          valoare = float(sheet['E' + str(i)].value)\n","          if valoare is not None and valoare < valoare_minima:\n","              valoare_minima = valoare\n","              indice_minim = i\n","\n","      sheet['E' + str(indice_minim)].font = openpyxl.styles.Font(bold=True)\n","\n","  workbook.save(path_export + '/centralizator-' + folder + '.xlsx')\n","\n","  val_accuracy = history.history['val_accuracy']\n","  val_loss = history.history['val_loss']\n","  epochs = range(1, len(val_accuracy) + 1)\n","  # Create subplots for accuracy and loss\n","  plt.figure(figsize=(12, 5))\n","\n","  # Plot Validation Accuracy\n","  plt.subplot(1, 2, 1)\n","  plt.plot(epochs, val_accuracy, 'b', label='Validation Accuracy')\n","  plt.title('Validation Accuracy')\n","  plt.xlabel('Epochs')\n","  plt.ylabel('Accuracy')\n","  plt.legend()\n","\n","  # Plot Validation Loss\n","  plt.subplot(1, 2, 2)\n","  plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","  plt.title('Validation Loss')\n","  plt.xlabel('Epochs')\n","  plt.ylabel('Loss')\n","  plt.legend()\n","\n","  # Show the plots\n","  plt.tight_layout()\n","  plt.show()\n","\n","def get_size(start_path = '.'):\n","    total_size = 0\n","    for dirpath, dirnames, filenames in os.walk(start_path):\n","        for f in filenames:\n","            fp = os.path.join(dirpath, f)\n","            # skip if it is symbolic link\n","            if not os.path.islink(fp):\n","                total_size += os.path.getsize(fp)\n","\n","    return total_size\n","\n","def get_flops(model_path):\n","    session = tf.compat.v1.Session()\n","    graph = tf.compat.v1.get_default_graph()\n","\n","    with graph.as_default():\n","        with session.as_default():\n","            model = tf.keras.models.load_model(model_path)\n","\n","            run_meta = tf.compat.v1.RunMetadata()\n","            opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n","\n","            flops = tf.compat.v1.profiler.profile(graph=graph, run_meta=run_meta, cmd='op', options=opts)\n","\n","            return flops.total_float_ops"],"metadata":{"cellView":"form","id":"PlDSfVAySbQV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title FFTConv2D Tensorflow Keras\n","\n","import functools\n","\n","from tensorflow.python.eager import context\n","from tensorflow.python.framework import tensor_shape\n","from tensorflow.python.keras import activations\n","from tensorflow.python.keras import backend\n","from tensorflow.python.keras import constraints\n","from tensorflow.python.keras import initializers\n","from tensorflow.python.keras import regularizers\n","from tensorflow.keras.layers import Layer\n","from tensorflow.keras.layers import InputSpec\n","# imports for backwards namespace compatibility\n","# pylint: disable=unused-import\n","from tensorflow.python.keras.layers.pooling import AveragePooling1D\n","from tensorflow.python.keras.layers.pooling import AveragePooling2D\n","from tensorflow.python.keras.layers.pooling import AveragePooling3D\n","from tensorflow.python.keras.layers.pooling import MaxPooling1D\n","from tensorflow.python.keras.layers.pooling import MaxPooling2D\n","from tensorflow.python.keras.layers.pooling import MaxPooling3D\n","# pylint: enable=unused-import\n","from tensorflow.python.keras.utils import conv_utils\n","from tensorflow.python.keras.utils import tf_utils\n","from tensorflow.python.ops import array_ops\n","from tensorflow.python.ops import array_ops_stack\n","from tensorflow.python.ops import nn\n","from tensorflow.python.ops import nn_ops\n","# pylint: disable=g-classes-have-attributes\n","from tensorflow.keras.utils import register_keras_serializable\n","\n","@register_keras_serializable()\n","class FFTConv2D(Layer):\n","\n","  def __init__(self,\n","               filters,\n","               kernel_size,\n","               strides=1,\n","               padding='valid',\n","               data_format=None,\n","               dilation_rate=1,\n","               groups=1,\n","               activation=None,\n","               use_bias=True,\n","               kernel_initializer='glorot_uniform',\n","               bias_initializer='zeros',\n","               kernel_regularizer=None,\n","               bias_regularizer=None,\n","               activity_regularizer=None,\n","               kernel_constraint=None,\n","               bias_constraint=None,\n","               trainable=True,\n","               name=None,\n","               conv_op=None,\n","               **kwargs):\n","    super(FFTConv2D, self).__init__(\n","        trainable=trainable,\n","        name=name,\n","        activity_regularizer=regularizers.get(activity_regularizer),\n","        **kwargs)\n","    rank = 2\n","    self.rank = rank\n","\n","    if isinstance(filters, float):\n","      filters = int(filters)\n","    if filters is not None and filters < 0:\n","      raise ValueError(f'Received a negative value for `filters`.'\n","                       f'Was expecting a positive value, got {filters}.')\n","    self.filters = filters\n","    self.groups = groups or 1\n","    self.kernel_size = conv_utils.normalize_tuple(\n","        kernel_size, rank, 'kernel_size')\n","    self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n","    self.padding = conv_utils.normalize_padding(padding)\n","    self.data_format = conv_utils.normalize_data_format(data_format)\n","    self.dilation_rate = conv_utils.normalize_tuple(\n","        dilation_rate, rank, 'dilation_rate')\n","\n","    self.activation = activations.get(activation)\n","    self.use_bias = use_bias\n","    self.conv_op = conv_op\n","\n","    self.kernel_initializer = initializers.get(kernel_initializer)\n","    self.bias_initializer = initializers.get(bias_initializer)\n","    self.kernel_regularizer = regularizers.get(kernel_regularizer)\n","    self.bias_regularizer = regularizers.get(bias_regularizer)\n","    self.kernel_constraint = constraints.get(kernel_constraint)\n","    self.bias_constraint = constraints.get(bias_constraint)\n","    self.input_spec = InputSpec(min_ndim=self.rank + 2)\n","\n","    self._validate_init()\n","    self._is_causal = self.padding == 'causal'\n","    self._channels_first = self.data_format == 'channels_first'\n","    self._tf_data_format = conv_utils.convert_data_format(\n","        self.data_format, self.rank + 2)\n","\n","  def _validate_init(self):\n","    if self.filters is not None and self.filters % self.groups != 0:\n","      raise ValueError(\n","          'The number of filters must be evenly divisible by the number of '\n","          'groups. Received: groups={}, filters={}'.format(\n","              self.groups, self.filters))\n","\n","    if not all(self.kernel_size):\n","      raise ValueError('The argument `kernel_size` cannot contain 0(s). '\n","                       'Received: %s' % (self.kernel_size,))\n","\n","    if not all(self.strides):\n","      raise ValueError('The argument `strides` cannot contains 0(s). '\n","                       'Received: %s' % (self.strides,))\n","\n","    if (self.padding == 'causal' and not isinstance(self,\n","                                                    (FFTConv1D, SeparableConv1D))):\n","      raise ValueError('Causal padding is only supported for `Conv1D`'\n","                       'and `SeparableConv1D`.')\n","\n","  def build(self, input_shape):\n","    input_shape = tensor_shape.TensorShape(input_shape)\n","    input_channel = self._get_input_channel(input_shape)\n","    if input_channel % self.groups != 0:\n","      raise ValueError(\n","          'The number of input channels must be evenly divisible by the number '\n","          'of groups. Received groups={}, but the input has {} channels '\n","          '(full input shape is {}).'.format(self.groups, input_channel,\n","                                             input_shape))\n","    kernel_shape = self.kernel_size + (input_channel // self.groups,\n","                                       self.filters)\n","\n","    self.kernel = self.add_weight(\n","        name='kernel',\n","        shape=kernel_shape,\n","        initializer=self.kernel_initializer,\n","        regularizer=self.kernel_regularizer,\n","        constraint=self.kernel_constraint,\n","        trainable=True,\n","        dtype=self.dtype)\n","    if self.use_bias:\n","      self.bias = self.add_weight(\n","          name='bias',\n","          shape=(self.filters,),\n","          initializer=self.bias_initializer,\n","          regularizer=self.bias_regularizer,\n","          constraint=self.bias_constraint,\n","          trainable=True,\n","          dtype=self.dtype)\n","    else:\n","      self.bias = None\n","    channel_axis = self._get_channel_axis()\n","    self.input_spec = InputSpec(min_ndim=self.rank + 2,\n","                                axes={channel_axis: input_channel})\n","\n","    # Convert Keras formats to TF native formats.\n","    if self.padding == 'causal':\n","      tf_padding = 'VALID'  # Causal padding handled in `call`.\n","    elif isinstance(self.padding, str):\n","      tf_padding = self.padding.upper()\n","    else:\n","      tf_padding = self.padding\n","    tf_dilations = list(self.dilation_rate)\n","    tf_strides = list(self.strides)\n","\n","    tf_op_name = self.__class__.__name__\n","    if tf_op_name == 'FFTConv1D':\n","      tf_op_name = 'fftconv1d'  # Backwards compat.\n","\n","    self._convolution_op = functools.partial(\n","        nn_ops.convolution_v2,\n","        strides=tf_strides,\n","        padding=tf_padding,\n","        dilations=tf_dilations,\n","        data_format=self._tf_data_format,\n","        name=tf_op_name)\n","    self.built = True\n","\n","  def call(self, inputs):\n","    input_shape = inputs.shape\n","\n","    if self._is_causal:  # Apply causal padding to inputs for Conv1D.\n","      inputs = array_ops.pad(inputs, self._compute_causal_padding(inputs))\n","\n","    outputs = self.fft_op(inputs, self.kernel)\n","\n","    if self.use_bias:\n","      output_rank = outputs.shape.rank\n","      if self.rank == 1 and self._channels_first:\n","        # nn.bias_add does not accept a 1D input tensor.\n","        bias = array_ops.reshape(self.bias, (1, self.filters, 1))\n","        outputs += bias\n","      else:\n","        # Handle multiple batch dimensions.\n","        if output_rank is not None and output_rank > 2 + self.rank:\n","\n","          def _apply_fn(o):\n","            return nn.bias_add(o, self.bias, data_format=self._tf_data_format)\n","\n","          outputs = conv_utils.squeeze_batch_dims(\n","              outputs, _apply_fn, inner_rank=self.rank + 1)\n","        else:\n","          outputs = nn.bias_add(\n","              outputs, self.bias, data_format=self._tf_data_format)\n","\n","    if not context.executing_eagerly():\n","      # Infer the static output shape:\n","      out_shape = self.compute_output_shape(input_shape)\n","      outputs.set_shape(out_shape)\n","\n","    if self.activation is not None:\n","      return self.activation(outputs)\n","    return outputs\n","\n","  @tf.function\n","  def fft_op(self, batch_images, kernels_outputs, strides=(1, 1), padding='valid', dilation_rate=(1, 1), data_format='channels_last'):\n","    kernels = tf.transpose(kernels_outputs, perm=[3,0,1,2])\n","\n","    def process_image(image):\n","      channels = tf.transpose(image, perm=[2,0,1])\n","\n","      def process_kernel(kernel):\n","        kernel_channels = tf.transpose(kernel, perm=[2,0,1])\n","\n","        def process_channel(args):\n","          channel, kernel_channel = args\n","\n","          channel = tf.cast(channel, dtype=tf.float32)\n","          kernel_channel = tf.cast(kernel_channel, dtype=tf.float32)\n","\n","          if padding == 'same':\n","              pad_height = max((kernel_channel.shape[0] - 1) // 2, 0)\n","              pad_width = max((kernel_channel.shape[1] - 1) // 2, 0)\n","              channel = tf.pad(channel, paddings=[[pad_height, pad_height], [pad_width, pad_width]])\n","          if channel.shape[0] is not None and channel.shape[1] is not None:\n","            if channel.shape[0] > kernel_channel.shape[0] or channel.shape[1] > kernel_channel.shape[1]:\n","              pad_height_kernel = max(channel.shape[0] - kernel_channel.shape[0], 0)\n","              pad_width_kernel = max(channel.shape[1] - kernel_channel.shape[1], 0)\n","              kernel_channel = tf.pad(kernel_channel, paddings=[[0, pad_height_kernel], [0, pad_width_kernel]])\n","            elif channel.shape[0] < kernel_channel.shape[0] or channel.shape[1] < kernel_channel.shape[1]:\n","              kernel_channel = kernel_channel[:channel.shape[0], :channel.shape[1]]\n","\n","          signal_fft = tf.signal.rfft2d(channel)\n","          kernel_fft = tf.signal.rfft2d(kernel_channel)\n","\n","          result_fft = signal_fft * kernel_fft\n","\n","          return tf.signal.irfft2d(result_fft)\n","\n","        output = tf.concat(tf.vectorized_map(process_channel, (channels, kernel_channels)), axis=-1)\n","        output = tf.transpose(output, perm=[1,2,0])\n","        return tf.reduce_sum(output, axis=-1)\n","\n","      return tf.concat(tf.vectorized_map(process_kernel, kernels), axis=-1)\n","\n","    result_batch = tf.concat(tf.vectorized_map(process_image, batch_images), axis=-1)\n","    result_batch = tf.transpose(result_batch, perm=[0,2,3,1])\n","\n","    return result_batch\n","\n","  def _spatial_output_shape(self, spatial_input_shape):\n","    return [\n","        conv_utils.conv_output_length(\n","            length,\n","            self.kernel_size[i],\n","            padding=self.padding,\n","            stride=self.strides[i],\n","            dilation=self.dilation_rate[i])\n","        for i, length in enumerate(spatial_input_shape)\n","    ]\n","\n","  def compute_output_shape(self, input_shape):\n","    input_shape = tensor_shape.TensorShape(input_shape).as_list()\n","    batch_rank = len(input_shape) - self.rank - 1\n","    if self.data_format == 'channels_last':\n","      return tensor_shape.TensorShape(\n","          input_shape[:batch_rank]\n","          + self._spatial_output_shape(input_shape[batch_rank:-1])\n","          + [self.filters])\n","    else:\n","      return tensor_shape.TensorShape(\n","          input_shape[:batch_rank] + [self.filters] +\n","          self._spatial_output_shape(input_shape[batch_rank + 1:]))\n","\n","  def _recreate_conv_op(self, inputs):  # pylint: disable=unused-argument\n","    return False\n","\n","  def get_config(self):\n","    config = {\n","        'filters':\n","            self.filters,\n","        'kernel_size':\n","            self.kernel_size,\n","        'strides':\n","            self.strides,\n","        'padding':\n","            self.padding,\n","        'data_format':\n","            self.data_format,\n","        'dilation_rate':\n","            self.dilation_rate,\n","        'groups':\n","            self.groups,\n","        'activation':\n","            activations.serialize(self.activation),\n","        'use_bias':\n","            self.use_bias,\n","        'kernel_initializer':\n","            initializers.serialize(self.kernel_initializer),\n","        'bias_initializer':\n","            initializers.serialize(self.bias_initializer),\n","        'kernel_regularizer':\n","            regularizers.serialize(self.kernel_regularizer),\n","        'bias_regularizer':\n","            regularizers.serialize(self.bias_regularizer),\n","        'activity_regularizer':\n","            regularizers.serialize(self.activity_regularizer),\n","        'kernel_constraint':\n","            constraints.serialize(self.kernel_constraint),\n","        'bias_constraint':\n","            constraints.serialize(self.bias_constraint),\n","        'trainable':\n","            self.trainable\n","    }\n","    base_config = super(FFTConv2D, self).get_config()\n","    full_config = dict(list(base_config.items()) + list(config.items()))\n","    return full_config\n","\n","  def _compute_causal_padding(self, inputs):\n","    \"\"\"Calculates padding for 'causal' option for 1-d conv layers.\"\"\"\n","    left_pad = self.dilation_rate[0] * (self.kernel_size[0] - 1)\n","    if getattr(inputs.shape, 'ndims', None) is None:\n","      batch_rank = 1\n","    else:\n","      batch_rank = len(inputs.shape) - 2\n","    if self.data_format == 'channels_last':\n","      causal_padding = [[0, 0]] * batch_rank + [[left_pad, 0], [0, 0]]\n","    else:\n","      causal_padding = [[0, 0]] * batch_rank + [[0, 0], [left_pad, 0]]\n","    return causal_padding\n","\n","  def _get_channel_axis(self):\n","    if self.data_format == 'channels_first':\n","      return -1 - self.rank\n","    else:\n","      return -1\n","\n","  def _get_input_channel(self, input_shape):\n","    channel_axis = self._get_channel_axis()\n","    if input_shape.dims[channel_axis].value is None:\n","      raise ValueError('The channel dimension of the inputs '\n","                       'should be defined. Found `None`.')\n","    return int(input_shape[channel_axis])\n","\n","  def _get_padding_op(self):\n","    if self.padding == 'causal':\n","      op_padding = 'valid'\n","    else:\n","      op_padding = self.padding\n","    if not isinstance(op_padding, (list, tuple)):\n","      op_padding = op_padding.upper()\n","    return op_padding"],"metadata":{"cellView":"form","id":"fdZvtPTrSskT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title VFFT-CNN\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Activation, BatchNormalization, Add, Attention\n","from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, SeparableConv2D  # straturi convolutionale si max-pooling\n","from tensorflow.keras.optimizers import RMSprop, SGD, Adadelta, Adam, Nadam\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers.schedules import ExponentialDecay\n","from tensorflow.keras.initializers import RandomNormal, HeNormal, GlorotUniform, GlorotNormal\n","from tensorflow.keras.regularizers import L2, L1L2\n","\n","kernel_regularizer=L2(1e-4)\n","kernel_initializer=GlorotUniform(seed=None)\n","drop_rate = 0.35  # Best value for CIFAR-100 after tuning in range 0.25 - 0.75!\n","psiz=4\n","stri=2\n","\n","#--------------------------  ------------------------------\n","# Define a convolutional block with FFTConv2D\n","def fft_conv_block(inputs, inputs_x, filters, kernel_size, padding, input_shape):\n","    x = FFTConv2D(filters=filters, kernel_size=(kernel_size, kernel_size), padding=padding, input_shape=input_shape, kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer)(inputs_x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = MaxPooling2D(pool_size=(psiz, psiz),strides=(stri,stri),padding=padding)(x)\n","    x = Dropout(drop_rate)(x)\n","\n","    return x, inputs\n","\n","def fft_block(inputs, filters, kernel_size, padding,input_shape):\n","    x = FFTConv2D(filters=filters, kernel_size=(kernel_size, kernel_size), padding=padding, input_shape=input_shape, kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer)(inputs)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","\n","    return x\n","\n","def create_v_cnn_fft_model(input_shape, num_classes, flat=1, fil=[20], nl=[1], hid=[], csize=15, padding='same'):\n","    inputs = Input(shape=input_shape)\n","    original_inputs = inputs\n","    x = inputs\n","\n","    # First macro-layer - connected to input\n","    if nl[0] > 0:\n","        x = fft_block(x, fil[0], csize, padding, input_shape)\n","        for _ in range(nl[0]):\n","            x = fft_block(x, fil[0], csize, padding, input_shape)\n","        x, inputs = fft_conv_block(inputs, x, fil[0], csize, padding, input_shape)\n","    else:\n","        x, inputs = fft_conv_block(inputs, x, fil[0], csize, padding, input_shape)\n","\n","    # The remaining macro-layers\n","    for layer in range(1, len(fil)):\n","        for _ in range(nl[layer]):\n","            x = fft_block(x, fil[layer], csize, padding, input_shape)\n","        x, inputs = fft_conv_block(inputs, x, fil[layer], csize, padding, input_shape)\n","\n","    # Exit classifier\n","    if flat == 1:\n","        x = Flatten()(x)\n","    elif flat == 0:\n","        x = GlobalAveragePooling2D()(x)\n","\n","    for units in hid:\n","        x = Dense(units, activation='relu')(x)\n","\n","    outputs = Dense(num_classes, activation='softmax')(x)\n","\n","    model = Model(inputs=original_inputs, outputs=outputs)\n","\n","    initial_learning_rate = 0.0001\n","    lr_schedule = ExponentialDecay(\n","        initial_learning_rate,\n","        decay_steps=10000,\n","        decay_rate=0.96,\n","        staircase=True)\n","\n","    model.compile(\n","        optimizer=tf.keras.optimizers.Adam(clipvalue=1.0, learning_rate=initial_learning_rate),\n","        loss='categorical_crossentropy',\n","        metrics=['accuracy']\n","    )\n","\n","    return model\n"],"metadata":{"cellView":"form","id":"ilJ-81tkS1BF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Benchmark dataset load\n","\n","dataset_path = '/mnt/c/local/path'\n","\n","# For dataset loaded from folder\n","train_data, validation_data, test_data, target_width, target_height, dataset_name, n_class = dataset(dataset_path, reload = False, width = 32, batch_size = 10, augment = 0, load_from_dir=True)\n","# For dataset loaded from Tensorflow API\n","# train_data, validation_data, test_data, target_width, target_height, dataset_name, n_class = dataset('imagenette', dataset_path, channels = 3, augment = 0)"],"metadata":{"id":"bPtr4gdfSey2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Benchmark\n","\n","epochs = 500\n","\n","vfft_cnn = create_v_cnn_fft_model(shape, num_classes=n_class, flat=1, fil=[3,6,10], nl=[1,0,0], hid=[], csize = 32, padding=\"same\")\n","vfft_cnn.summary()  #  flat=1, fil=[3,6,10], nl=[1,0,0], hid=[], csize = 64 - 91%\n","train('VFFT-CNN', vfft_cnn, epochs, train_data, validation_data, test_data, dataset_name, dataset_path, batch_size = 64, use_generator_from_dir=True)"],"metadata":{"id":"c4srtPLOSjtN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Confusion Matrix\n","import tensorflow as tf\n","import numpy as np\n","\n","model_path = '/mnt/c/local/path/model.keras'\n","model = tf.keras.models.load_model(model_path)\n","\n","batch_size = 20\n","\n","labels=(np.dot(test_data[1],np.array(range(n_class)).T)).astype('int16')\n","pred= model.predict(test_data[0], batch_size=batch_size)\n","predicted_class_indices=np.argmax(pred,axis=1)\n","from sklearn.metrics import classification_report, confusion_matrix\n","C=confusion_matrix(predicted_class_indices,labels)\n","print (C)\n","print('Classification Report')\n","print(classification_report(labels,predicted_class_indices ))\n"],"metadata":{"cellView":"form","id":"Lxq44YVMTBR0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title CNN Filters plot\n","\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","\n","# Load your trained model\n","model = tf.keras.models.load_model('/mnt/c/local/path/model.keras')\n","\n","# Get the convolutional layers\n","# conv_layers = [layer for layer in model.layers if isinstance(layer,tf.keras.layers.Conv2D)]\n","conv_layers = [layer for layer in model.layers if isinstance(layer,FFTConv2D)]\n","\n","# Visualize filters\n","for i, layer in enumerate(conv_layers):\n","    filters, biases = layer.get_weights()\n","    # Normalize filter values to 0-1 so they can be visualized\n","    filters_min, filters_max = filters.min(), filters.max()\n","    filters = (filters - filters_min) / (filters_max - filters_min)\n","\n","    # Plot filters\n","    n_filters = filters.shape[3]\n","    for j in range(n_filters):\n","        plt.subplot(n_filters, len(conv_layers), i + 1)\n","        plt.imshow(filters[:, :, 0, j], cmap='gray')\n","        plt.axis('off')\n","plt.show()"],"metadata":{"cellView":"form","id":"Vtg3NyE3TE6G"},"execution_count":null,"outputs":[]}]}